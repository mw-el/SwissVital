#!/usr/bin/env python3
"""
Script: merge_i18n_translations.py

Purpose:
  This script processes multiple OpenDocument Spreadsheet (ODS) files containing translations
  and merges them into structured JSON translation files for Hugo.

Features:
  - Accepts either a **directory** or selected **individual files**.
  - Organizes translations **by file-based sections**, using the ODS filename as the section name.
  - If JSON files already exist, the script:
      - Lists existing sections that are **not part of the new source files**.
      - Lists **new fields** added in the updated files.
      - Preserves **existing translations** for languages not present in the new ODS files.
      - Asks the user whether to:
        - **(A) Fully regenerate** JSON files, deleting unreferenced sections.
        - **(B) Only update existing sections**, preserving unrelated sections.
  - Ensures **no data loss** by confirming changes before applying them.
  - Handles encoding issues and malformed JSON files.
  - Always produces translation files named **de.json, en.json, fr.json, etc.**
  - **If no existing JSON files are found, it will create them automatically.**
  - **Ensures updates do not remove valid translations by mistake.**
  - **Guarantees that JSON files are written even if no files existed before.**

Dependencies:
  pip install pandas odfpy

Usage:
  1. Select an ODS file or directory containing ODS files.
  2. The script will scan, merge, and ask for confirmation before modifying JSON files.
  3. It will update **i18n/{language}.json** with structured sections named after each ODS file.

Author: AI-Generated with Custom Enhancements
"""

import os
import json
import logging
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")

def select_files_or_directory():
    """Let the user choose whether to select a directory or individual ODS files."""
    root = tk.Tk()
    root.title("Select Input")

    # We'll store the final selection here
    selection = []

    def on_select_directory():
        dir_path = filedialog.askdirectory(title="Select Directory Containing ODS Files")
        if not dir_path:
            logging.error("No directory selected. Exiting.")
            exit(1)
        root.destroy()
        files_in_dir = [
            os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith(".ods")
        ]
        selection.extend(files_in_dir)

    def on_select_files():
        file_paths = filedialog.askopenfilenames(
            title="Select ODS Translation Files",
            filetypes=[("ODS files", "*.ods")]
        )
        if not file_paths:
            logging.error("No files selected. Exiting.")
            exit(1)
        root.destroy()
        selection.extend(file_paths)

    def on_close():
        root.destroy()
        exit(1)

    frame = tk.Frame(root)
    frame.pack(padx=20, pady=20)

    label = tk.Label(frame, text="Choose how you want to select the ODS translations:")
    label.pack(pady=10)

    dir_button = tk.Button(frame, text="Select Folder", command=on_select_directory)
    dir_button.pack(side="left", padx=10)

    file_button = tk.Button(frame, text="Select ODS Files", command=on_select_files)
    file_button.pack(side="left", padx=10)

    root.protocol("WM_DELETE_WINDOW", on_close)
    root.mainloop()
    return selection

def read_ods_file(filepath):
    """
    Read an ODS translation file and return a dictionary
    in the format:
        {
          "en": {
            "<filename>": {
              "key1": "some text",
              "key2": "some other text"
            }
          },
          "de": {
            "<filename>": {
              "key1": "irgendwas",
              ...
            }
          },
          ...
        }
    """
    try:
        df = pd.read_excel(filepath, engine="odf")
        if len(df.columns) < 2 or df.columns[0].lower() != "key":
            logging.error(f"Invalid format in {filepath}. Expected 'key' column and at least one language column.")
            return None
        
        filename = os.path.splitext(os.path.basename(filepath))[0]
        languages = df.columns[1:]
        # Initialize a dictionary for each language with a nested dict for the filename
        translations = {lang: {filename: {}} for lang in languages}
        
        for _, row in df.iterrows():
            key = str(row["key"]).strip()
            if not key:
                continue
            for lang in languages:
                translations[lang][filename][key] = str(row[lang]).strip() if not pd.isna(row[lang]) else ""
        
        return translations
    except Exception as e:
        logging.error(f"Failed to process {filepath}: {e}")
        return None

def merge_translations(existing_data, new_data):
    """
    Merge new translations into existing JSON structure without data loss.
    new_data comes in the format:
       {
         lang: {
           filename: { key1: val1, ... }
         }
       }
    so we need to merge each filename section for each language accordingly.
    """
    for lang, sections in new_data.items():
        if lang not in existing_data:
            existing_data[lang] = {}
        for section_name, entries in sections.items():
            if section_name not in existing_data[lang]:
                existing_data[lang][section_name] = {}
            existing_data[lang][section_name].update(entries)
    return existing_data

def write_json_files(output_dir, translations):
    """
    Write out JSON files for each language:
       i18n/<lang>.json
    Each file will have top-level keys for the filenames, e.g.:
       {
         "filename1": { "key1": "value1", ... },
         "filename2": { "keyA": "valueA", ... }
       }
    """
    os.makedirs(output_dir, exist_ok=True)
    for lang, data in translations.items():
        filepath = os.path.join(output_dir, f"{lang}.json")
        try:
            with open(filepath, "w", encoding="utf-8") as json_file:
                json.dump(data, json_file, ensure_ascii=False, indent=2)
            logging.info(f"Created or updated: {filepath}")
        except Exception as e:
            logging.error(f"Failed to write {filepath}: {e}")

def main():
    logging.info("Starting translation processing...")
    files = select_files_or_directory()
    i18n_dir = os.path.join(os.path.dirname(__file__), "../i18n")
    
    # Load existing JSON data, or initialize empty if none exist
    existing_json_files = {}
    if not os.path.exists(i18n_dir):
        os.makedirs(i18n_dir, exist_ok=True)
    
    for file in os.listdir(i18n_dir):
        if file.endswith(".json"):
            lang = os.path.splitext(file)[0]
            try:
                with open(os.path.join(i18n_dir, file), "r", encoding="utf-8") as f:
                    existing_json_files[lang] = json.load(f)
            except json.JSONDecodeError:
                logging.warning(f"Skipping invalid JSON file: {file}")
    
    # Process selected files
    new_translations = {}
    for file in files:
        result = read_ods_file(file)
        if result:
            new_translations = merge_translations(new_translations, result)
    
    # Merge new_translations into existing_json_files
    merged_data = merge_translations(existing_json_files, new_translations)
    
    # Write updated or newly created JSON files
    write_json_files(i18n_dir, merged_data)
    logging.info("âœ… Translation JSON files successfully created or updated!")

if __name__ == "__main__":
    main()
